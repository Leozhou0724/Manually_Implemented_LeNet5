Because of the performance restriction of numpy and my laptop
this nerual network based on numpy runs very slowly, 
and it's impossible for me to finish even one epoch(it's estimated to take 10,000 seconds)
	
So I run the training program for some time. The results are below.

Batch means the number of data has been trained. So it shows training 
2000 data takes 343s which is 3.3% of all the 60,000 dataset.

But the loss shows that this model does work, the overall trend of the loss does decrease,
while it maybe unstable because of the restricted number of training data.
 


Epoch:0  Batch:1    ( 0.001667% )    Loss:2.861995    Runtime:3.24s
Epoch:0  Batch:21    ( 0.035000% )    Loss:2.312338    Runtime:6.46s
Epoch:0  Batch:41    ( 0.068333% )    Loss:2.293660    Runtime:9.67s
Epoch:0  Batch:61    ( 0.101667% )    Loss:2.367850    Runtime:12.89s
Epoch:0  Batch:81    ( 0.135000% )    Loss:2.239376    Runtime:16.11s
Epoch:0  Batch:101    ( 0.168333% )    Loss:2.024684    Runtime:19.33s
Epoch:0  Batch:121    ( 0.201667% )    Loss:2.239738    Runtime:22.54s
Epoch:0  Batch:141    ( 0.235000% )    Loss:2.179049    Runtime:25.77s
Epoch:0  Batch:161    ( 0.268333% )    Loss:2.210369    Runtime:28.98s
Epoch:0  Batch:181    ( 0.301667% )    Loss:2.287664    Runtime:32.20s
Epoch:0  Batch:201    ( 0.335000% )    Loss:2.122423    Runtime:35.41s
Epoch:0  Batch:221    ( 0.368333% )    Loss:2.254846    Runtime:38.63s
Epoch:0  Batch:241    ( 0.401667% )    Loss:2.088890    Runtime:41.84s
Epoch:0  Batch:261    ( 0.435000% )    Loss:2.109991    Runtime:45.06s
Epoch:0  Batch:281    ( 0.468333% )    Loss:1.609916    Runtime:48.29s
Epoch:0  Batch:301    ( 0.501667% )    Loss:1.991831    Runtime:51.62s
Epoch:0  Batch:321    ( 0.535000% )    Loss:2.308771    Runtime:55.11s
Epoch:0  Batch:341    ( 0.568333% )    Loss:2.173141    Runtime:58.37s
Epoch:0  Batch:361    ( 0.601667% )    Loss:1.727534    Runtime:61.64s
Epoch:0  Batch:381    ( 0.635000% )    Loss:1.511966    Runtime:64.85s
Epoch:0  Batch:401    ( 0.668333% )    Loss:2.067997    Runtime:68.05s
Epoch:0  Batch:421    ( 0.701667% )    Loss:2.277882    Runtime:71.27s
Epoch:0  Batch:441    ( 0.735000% )    Loss:2.341856    Runtime:74.59s
Epoch:0  Batch:461    ( 0.768333% )    Loss:2.285234    Runtime:77.81s
Epoch:0  Batch:481    ( 0.801667% )    Loss:2.311207    Runtime:81.02s
Epoch:0  Batch:501    ( 0.835000% )    Loss:2.224984    Runtime:84.28s
Epoch:0  Batch:521    ( 0.868333% )    Loss:2.207295    Runtime:88.20s
Epoch:0  Batch:541    ( 0.901667% )    Loss:2.209761    Runtime:91.75s
Epoch:0  Batch:561    ( 0.935000% )    Loss:2.774883    Runtime:95.73s
Epoch:0  Batch:581    ( 0.968333% )    Loss:2.301742    Runtime:99.00s
Epoch:0  Batch:601    ( 1.001667% )    Loss:2.172821    Runtime:102.23s
Epoch:0  Batch:621    ( 1.035000% )    Loss:2.349057    Runtime:105.44s
Epoch:0  Batch:641    ( 1.068333% )    Loss:2.353453    Runtime:108.88s
Epoch:0  Batch:661    ( 1.101667% )    Loss:2.173092    Runtime:112.44s
Epoch:0  Batch:681    ( 1.135000% )    Loss:2.350878    Runtime:116.25s
Epoch:0  Batch:701    ( 1.168333% )    Loss:2.165628    Runtime:120.06s
Epoch:0  Batch:721    ( 1.201667% )    Loss:2.181503    Runtime:123.31s
Epoch:0  Batch:741    ( 1.235000% )    Loss:2.226172    Runtime:126.60s
Epoch:0  Batch:761    ( 1.268333% )    Loss:2.100867    Runtime:129.82s
Epoch:0  Batch:781    ( 1.301667% )    Loss:2.215880    Runtime:133.05s
Epoch:0  Batch:801    ( 1.335000% )    Loss:2.106936    Runtime:136.47s
Epoch:0  Batch:821    ( 1.368333% )    Loss:1.693797    Runtime:139.80s
Epoch:0  Batch:841    ( 1.401667% )    Loss:1.995721    Runtime:143.29s
Epoch:0  Batch:861    ( 1.435000% )    Loss:2.034301    Runtime:146.97s
Epoch:0  Batch:881    ( 1.468333% )    Loss:1.895898    Runtime:150.39s
Epoch:0  Batch:901    ( 1.501667% )    Loss:1.763651    Runtime:153.63s
Epoch:0  Batch:921    ( 1.535000% )    Loss:1.642075    Runtime:157.25s
Epoch:0  Batch:941    ( 1.568333% )    Loss:1.378071    Runtime:160.49s
Epoch:0  Batch:961    ( 1.601667% )    Loss:1.947471    Runtime:163.72s
Epoch:0  Batch:981    ( 1.635000% )    Loss:2.220888    Runtime:167.05s
Epoch:0  Batch:1001    ( 1.668333% )    Loss:1.851239    Runtime:170.31s
Epoch:0  Batch:1021    ( 1.701667% )    Loss:2.297099    Runtime:174.12s
Epoch:0  Batch:1041    ( 1.735000% )    Loss:1.390147    Runtime:177.36s
Epoch:0  Batch:1061    ( 1.768333% )    Loss:2.182457    Runtime:180.85s
Epoch:0  Batch:1081    ( 1.801667% )    Loss:1.769916    Runtime:184.29s
Epoch:0  Batch:1101    ( 1.835000% )    Loss:2.132022    Runtime:187.65s
Epoch:0  Batch:1121    ( 1.868333% )    Loss:2.237659    Runtime:191.03s
Epoch:0  Batch:1141    ( 1.901667% )    Loss:1.966287    Runtime:194.59s
Epoch:0  Batch:1161    ( 1.935000% )    Loss:1.897626    Runtime:198.13s
Epoch:0  Batch:1181    ( 1.968333% )    Loss:1.962872    Runtime:202.26s
Epoch:0  Batch:1201    ( 2.001667% )    Loss:1.893307    Runtime:205.50s
Epoch:0  Batch:1221    ( 2.035000% )    Loss:1.641718    Runtime:208.73s
Epoch:0  Batch:1241    ( 2.068333% )    Loss:1.456879    Runtime:212.12s
Epoch:0  Batch:1261    ( 2.101667% )    Loss:1.681768    Runtime:215.49s
Epoch:0  Batch:1281    ( 2.135000% )    Loss:1.469746    Runtime:218.84s
Epoch:0  Batch:1301    ( 2.168333% )    Loss:1.792089    Runtime:222.23s
Epoch:0  Batch:1321    ( 2.201667% )    Loss:1.637528    Runtime:226.51s
Epoch:0  Batch:1341    ( 2.235000% )    Loss:2.102146    Runtime:231.32s
Epoch:0  Batch:1361    ( 2.268333% )    Loss:2.145204    Runtime:236.03s
Epoch:0  Batch:1381    ( 2.301667% )    Loss:2.229327    Runtime:239.32s
Epoch:0  Batch:1401    ( 2.335000% )    Loss:2.105697    Runtime:242.75s
Epoch:0  Batch:1421    ( 2.368333% )    Loss:2.107229    Runtime:246.18s
Epoch:0  Batch:1441    ( 2.401667% )    Loss:2.051644    Runtime:249.87s
Epoch:0  Batch:1461    ( 2.435000% )    Loss:2.189533    Runtime:253.18s
Epoch:0  Batch:1481    ( 2.468333% )    Loss:2.029829    Runtime:256.42s
Epoch:0  Batch:1501    ( 2.501667% )    Loss:2.229454    Runtime:259.66s
Epoch:0  Batch:1521    ( 2.535000% )    Loss:2.109516    Runtime:262.90s
Epoch:0  Batch:1541    ( 2.568333% )    Loss:2.086384    Runtime:266.14s
Epoch:0  Batch:1561    ( 2.601667% )    Loss:1.743512    Runtime:269.62s
Epoch:0  Batch:1581    ( 2.635000% )    Loss:2.146559    Runtime:273.23s
Epoch:0  Batch:1601    ( 2.668333% )    Loss:1.877960    Runtime:276.52s
Epoch:0  Batch:1621    ( 2.701667% )    Loss:2.346272    Runtime:279.77s
Epoch:0  Batch:1641    ( 2.735000% )    Loss:1.689536    Runtime:283.16s
Epoch:0  Batch:1661    ( 2.768333% )    Loss:1.739171    Runtime:286.79s
Epoch:0  Batch:1681    ( 2.801667% )    Loss:1.268169    Runtime:290.03s
Epoch:0  Batch:1701    ( 2.835000% )    Loss:1.452602    Runtime:293.36s
Epoch:0  Batch:1721    ( 2.868333% )    Loss:1.090802    Runtime:296.86s
Epoch:0  Batch:1741    ( 2.901667% )    Loss:1.291804    Runtime:300.40s
Epoch:0  Batch:1761    ( 2.935000% )    Loss:0.985096    Runtime:303.91s
Epoch:0  Batch:1781    ( 2.968333% )    Loss:1.853304    Runtime:307.48s
Epoch:0  Batch:1801    ( 3.001667% )    Loss:3.365271    Runtime:310.71s
Epoch:0  Batch:1821    ( 3.035000% )    Loss:2.084713    Runtime:313.92s
Epoch:0  Batch:1841    ( 3.068333% )    Loss:2.092151    Runtime:317.14s
Epoch:0  Batch:1861    ( 3.101667% )    Loss:2.002915    Runtime:320.35s
Epoch:0  Batch:1881    ( 3.135000% )    Loss:1.856525    Runtime:323.77s
Epoch:0  Batch:1901    ( 3.168333% )    Loss:1.779403    Runtime:327.01s
Epoch:0  Batch:1921    ( 3.201667% )    Loss:1.590287    Runtime:330.22s
Epoch:0  Batch:1941    ( 3.235000% )    Loss:1.765717    Runtime:333.45s
Epoch:0  Batch:1961    ( 3.268333% )    Loss:1.707493    Runtime:336.67s
Epoch:0  Batch:1981    ( 3.301667% )    Loss:1.212449    Runtime:339.90s
Epoch:0  Batch:2001    ( 3.335000% )    Loss:1.290035    Runtime:343.12s
